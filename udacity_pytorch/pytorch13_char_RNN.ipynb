{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1985223,\n",
       " 'Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "with open('data/texts/anna.txt') as data:\n",
    "    text = data.read()\n",
    "    \n",
    "len(text), text[:89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vocabulary (list of unique characters in the text)\n",
    "vocab = tuple(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(arr, p=0.1):\n",
    "    \"\"\"split data according to desired percentate p\"\"\"\n",
    "    split_idx = int(len(arr) * p)\n",
    "    train_data = arr[:-split_idx]\n",
    "    valid_data = arr[-split_idx:]\n",
    "    return [ch for ch in train_data], [ch for ch in valid_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1786701,), (198522,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_x, v_x = train_val_split(text)\n",
    "t_x, v_x = np.array(t_x), np.array(v_x)\n",
    "\n",
    "t_x.shape, v_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_targets(sequence):\n",
    "    \"\"\"\n",
    "    get sequence of shape (n_samples, n_features) and return\n",
    "    target sequence of same shape with wrap-around where required.\n",
    "    \"\"\"\n",
    "    wrap = sequence[0]\n",
    "    return np.append(sequence[1:], wrap).reshape(sequence.shape)\n",
    "\n",
    "def get_batches(arr, batch_size, seq_length, encoder=None):\n",
    "    \"\"\"\n",
    "    Divide 1 feature sequence data into batches. Each batch will contain\n",
    "    `n=batch_size` sequences, each with length `m=seq_len`.\n",
    "    \"\"\"\n",
    " \n",
    "    n_chars   = batch_size * seq_length          # -> Total # chars per batch\n",
    "    n_batches = int(np.floor(len(arr)/ n_chars)) # -> Total batches possible \n",
    "    n_keep    = n_chars * n_batches              # -> Cutoff for even batches\n",
    "    \n",
    "    inputs  = arr[:n_keep]\n",
    "    targets = create_targets(arr)[:n_keep]\n",
    "    \n",
    "    if encoder is not None:\n",
    "        n_cats = len(encoder.categories_[0])\n",
    "        inputs = encoder.transform(inputs.reshape(-1, 1))\n",
    "        inputs = inputs.reshape(batch_size, -1, n_cats)\n",
    "    else:\n",
    "        inputs = inputs.reshape(batch_size, -1)\n",
    "        \n",
    "    targets = targets.reshape(batch_size, -1)\n",
    "    \n",
    "    for b in range(0, inputs.shape[1], seq_length): \n",
    "        x = torch.tensor(inputs[:, b: b + seq_length], dtype=torch.float32)\n",
    "        y = torch.tensor(targets[:, b: b + seq_length], dtype=torch.float32)   \n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class charNN(nn.Module):\n",
    "    def __init__(self, vocab, hidden_size, n_layers, dropout=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab = vocab\n",
    "        self.int2char = dict(enumerate(vocab))\n",
    "        self.char2int = {ch : i for i, ch in self.int2char.items()}\n",
    "        self.vocab_length = len(vocab)\n",
    "        \n",
    "        oh_keys = np.array([i for i, _ in enumerate(vocab)])\n",
    "        self.encoder = OneHotEncoder(sparse=False).fit(oh_keys.reshape(-1, 1))\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.vocab_length, hidden_size, n_layers, batch_first=True)\n",
    "        self.fc   = nn.Linear(hidden_size, self.vocab_length)\n",
    "        self.do   = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        x, hidden = self.lstm(x, hidden)     # -> (n_batches, seq_len, hidden_size)\n",
    "        x = self.do(x)\n",
    "        x = x.reshape(-1, self.hidden_size)  # -> (n_batches * seq_len, hidden_size)\n",
    "        x = self.fc(x)                       # -> (n_batches * seq_len, vocab_length)\n",
    "        return x, hidden    \n",
    "    \n",
    "    def train_model(self, train_data, batch_size, \n",
    "                    seq_len, epochs, lr=0.001, clip=5, valid=None):\n",
    "           \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self = self.to(device)\n",
    "        \n",
    "        opt = optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        valid_loss = []\n",
    "        train_loss = []\n",
    "        \n",
    "        train_data = np.array([self.char2int[c] for c in train_data])\n",
    "        if valid is not None:\n",
    "            valid = np.array([self.char2int[c] for c in valid])\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            \n",
    "            running_t_loss = 0\n",
    "            running_v_loss = 0\n",
    "            \n",
    "            if valid is not None:\n",
    "                v_hs = None\n",
    "                self.eval()\n",
    "                with torch.no_grad():\n",
    "                    batches = get_batches(valid, batch_size, seq_len, encoder=self.encoder)\n",
    "                    for x, y in batches:\n",
    "                        x, y = x.to(device), y.to(device)\n",
    "                        out, v_hs = self(x, v_hs)\n",
    "                        loss = criterion(out, y.view(batch_size * seq_len).long())\n",
    "                        running_v_loss += loss.item()\n",
    "            \n",
    "            self.train()\n",
    "            hs = None\n",
    "            batches = get_batches(train_data, \n",
    "                                  batch_size, \n",
    "                                  seq_len, \n",
    "                                  encoder=self.encoder)\n",
    "            \n",
    "            for x, y in batches:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                opt.zero_grad()\n",
    "                out, hs = self(x, hs)\n",
    "                hs = tuple([h_n.data for h_n in hs])\n",
    "                loss = criterion(out, y.view(batch_size * seq_len).long())\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(self.parameters(), clip)\n",
    "                opt.step()\n",
    "                running_t_loss += loss.item()\n",
    "            \n",
    "            train_loss.append(np.mean(running_t_loss))\n",
    "            valid_loss.append(np.mean(running_v_loss))\n",
    "            \n",
    "            if e % np.floor(epochs / 10) == 0:\n",
    "                print(f'------------ EPOCH {e} --------------')\n",
    "                print(f'Training Loss: {train_loss[-1]}')\n",
    "                print(f'Validation Loss: {valid_loss[-1]}')\n",
    "                try:\n",
    "                    if valid_loss[-1] < valid_loss[-2]:\n",
    "                        print('Validation Loss Decreased')\n",
    "                except IndexError:\n",
    "                    pass\n",
    "        \n",
    "        plt.plot(train_loss, label='Training Loss')\n",
    "        plt.plot(valid_loss, label='Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def predict(self, char, top_k=None, hs=None):\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.to(device)\n",
    "        self.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            int_val = torch.tensor(self.char2int[char])\n",
    "            x = int_val.reshape(-1, 1)\n",
    "            x = self.encoder.transform(x)\n",
    "            x = x.reshape(1, 1, -1)\n",
    "            x = torch.tensor(x, dtype=torch.float32)\n",
    "            x = x.to(device)\n",
    "\n",
    "            hs = None\n",
    "            out, hs = self(x, hs)\n",
    "\n",
    "            ps   = F.softmax(out, dim=1).squeeze()\n",
    "            \n",
    "            if top_k is None:\n",
    "                choices = np.arange(len(self.vocab))\n",
    "            else:\n",
    "                ps, choices = ps.topk(top_k)\n",
    "                choices = choices.cpu().numpy()\n",
    "            \n",
    "            ps = ps.cpu().numpy()\n",
    "            \n",
    "            char = np.random.choice(choices, p=ps/ps.sum())\n",
    "            char = self.int2char[char]\n",
    "\n",
    "        return char, hs\n",
    "    \n",
    "    def sample(self, length, top_k=None, primer='The '):\n",
    "        hs = None\n",
    "        for px in primer:\n",
    "            out, hs = self.predict(px, hs=hs)\n",
    "        \n",
    "        chars = [out]\n",
    "        for ix in range(length):\n",
    "            char, out = self.predict(chars[-1], top_k=top_k, hs=hs)\n",
    "            chars.append(char)\n",
    "        \n",
    "        return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "charNN(\n",
       "  (lstm): LSTM(83, 390, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=390, out_features=83, bias=True)\n",
       "  (do): Dropout(p=0.7, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = 390\n",
    "n_layers = 2\n",
    "\n",
    "model = charNN(vocab, n_hidden, n_layers, dropout=0.7)\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ EPOCH 0 --------------\n",
      "Training Loss: 436.0718319416046\n",
      "Validation Loss: 66.21571254730225\n",
      "------------ EPOCH 3 --------------\n",
      "Training Loss: 272.86003839969635\n",
      "Validation Loss: 30.448553800582886\n",
      "Validation Loss Decreased\n",
      "------------ EPOCH 6 --------------\n",
      "Training Loss: 225.98951613903046\n",
      "Validation Loss: 24.884556770324707\n",
      "Validation Loss Decreased\n",
      "------------ EPOCH 9 --------------\n",
      "Training Loss: 202.78993332386017\n",
      "Validation Loss: 22.5654479265213\n",
      "Validation Loss Decreased\n",
      "------------ EPOCH 12 --------------\n",
      "Training Loss: 189.19160079956055\n",
      "Validation Loss: 21.262558698654175\n",
      "Validation Loss Decreased\n",
      "------------ EPOCH 15 --------------\n",
      "Training Loss: 180.08684873580933\n",
      "Validation Loss: 20.570603370666504\n",
      "Validation Loss Decreased\n",
      "------------ EPOCH 18 --------------\n",
      "Training Loss: 173.64980471134186\n",
      "Validation Loss: 20.175092816352844\n",
      "Validation Loss Decreased\n",
      "------------ EPOCH 21 --------------\n",
      "Training Loss: 168.3565844297409\n",
      "Validation Loss: 19.91546320915222\n",
      "Validation Loss Decreased\n",
      "------------ EPOCH 24 --------------\n",
      "Training Loss: 163.85073590278625\n",
      "Validation Loss: 19.810381770133972\n",
      "Validation Loss Decreased\n",
      "------------ EPOCH 27 --------------\n",
      "Training Loss: 160.39099216461182\n",
      "Validation Loss: 19.82862639427185\n",
      "------------ EPOCH 30 --------------\n",
      "Training Loss: 157.26869320869446\n",
      "Validation Loss: 19.87799894809723\n",
      "------------ EPOCH 33 --------------\n",
      "Training Loss: 154.34548199176788\n",
      "Validation Loss: 19.932873368263245\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.train_model(t_x, 128, 100, 35, valid=v_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_file = 'LSTM_35_epoch.net'\n",
    "\n",
    "checkpoint = {\n",
    "    'vocab'     : model.vocab,\n",
    "    'n_hidden'  : model.hidden_size,\n",
    "    'n_layers'  : model.n_layers,\n",
    "    'state_dict': model.state_dict()\n",
    "}\n",
    "\n",
    "with open(f'saved/{saved_file}', 'wb') as f:\n",
    "    torch.save(checkpoint, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved/LSTM_35_epoch.net', 'rb') as f:\n",
    "    checkpoint = torch.load(f)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = charNN(vocab, checkpoint['n_hidden'], checkpoint['n_layers'])\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eshinenore anathanerinous athonorithathanerinirerareroureronononovele helothanelithout thalonele Alinonelaly thelaneneninene Athy harerithelishininenathirathatelorine tist henarere Alares thigininonot Anes.\\nAlaratelathery\\nTthelone Ts,\"\\nthenelinonenotherinorelithashesthy henone he Tithelathe helinerite he halonalougiges,\" Aly hes Anorithinithelenouthas alove Alarathenely thatharithelithonovas, Alenererithathe haronithe halale Talalares alelinalingeline harene he harerathererashes thary,\" tharenes Alele astelenere Athenouronite henerelinonorely. Ts halerinininores.\\nt are he has as, he Alinenenelathanithonarinonineninathelathinonithes Alinithatherelathanelononenerithe ales... hone ary hinigrithene Alitinatharonerinenenerinothene atenarorine Alinge Ts honelithas Tsthely t\\'thathine t\\'s athelaninone thononithery henonaleneralinenenonitinenes teralone are helenes, Angithathenoverinalinesthares anes Tinonine he Alinorerathatharis honone aras Tstine Arithalerinorothas thonorenithalas Ttheralathe'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sample(1000, top_k=5, primer='The bird sang us a song')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
