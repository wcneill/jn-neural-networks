{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1985223,\n",
       " 'Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "with open('data/texts/anna.txt') as data:\n",
    "    text = data.read()\n",
    "    \n",
    "len(text), text[:89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s',\n",
       " '8',\n",
       " ';',\n",
       " 'v',\n",
       " '*',\n",
       " '7',\n",
       " '@',\n",
       " '4',\n",
       " 'f',\n",
       " 'Z',\n",
       " 'p',\n",
       " 'd',\n",
       " 'k',\n",
       " '5',\n",
       " 'w',\n",
       " 'N',\n",
       " 'i',\n",
       " ')',\n",
       " 'u',\n",
       " '\\n',\n",
       " 'H',\n",
       " 'K',\n",
       " '!',\n",
       " '_',\n",
       " '`',\n",
       " 'F',\n",
       " 't',\n",
       " 'Q',\n",
       " 'E',\n",
       " 'n',\n",
       " 'l',\n",
       " 'M',\n",
       " 'm',\n",
       " 'P',\n",
       " 'B',\n",
       " '/',\n",
       " '$',\n",
       " ' ',\n",
       " 'r',\n",
       " '%',\n",
       " 'y',\n",
       " 'D',\n",
       " 'z',\n",
       " '0',\n",
       " 'J',\n",
       " 'G',\n",
       " 'b',\n",
       " 'R',\n",
       " 'o',\n",
       " 'C',\n",
       " \"'\",\n",
       " '1',\n",
       " 'c',\n",
       " 'q',\n",
       " 'V',\n",
       " 'x',\n",
       " 'e',\n",
       " 'S',\n",
       " 'T',\n",
       " '?',\n",
       " '3',\n",
       " 'j',\n",
       " '&',\n",
       " 'U',\n",
       " '(',\n",
       " 'Y',\n",
       " 'I',\n",
       " ':',\n",
       " 'W',\n",
       " '.',\n",
       " 'g',\n",
       " '-',\n",
       " '2',\n",
       " 'O',\n",
       " '\"',\n",
       " '6',\n",
       " 'a',\n",
       " 'L',\n",
       " 'h',\n",
       " 'X',\n",
       " ',',\n",
       " '9',\n",
       " 'A')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get vocabulary (list of unique characters in the text)\n",
    "vocab = tuple(set(text))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(arr, p=0.1):\n",
    "    \"\"\"split data according to desired percentate p\"\"\"\n",
    "    split_idx = int(len(arr) * p)\n",
    "    train_data = arr[:-split_idx]\n",
    "    valid_data = arr[-split_idx:]\n",
    "    return [ch for ch in train_data], [ch for ch in valid_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1786701,), (198522,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_x, v_x = train_val_split(text)\n",
    "t_x, v_x = np.array(t_x), np.array(v_x)\n",
    "\n",
    "t_x.shape, v_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_targets(sequence):\n",
    "    \"\"\"\n",
    "    get sequence of shape (n_samples, n_features) and return\n",
    "    target sequence of same shape with wrap-around where required.\n",
    "    \"\"\"\n",
    "    wrap = sequence[0]\n",
    "    return np.append(sequence[1:], wrap).reshape(sequence.shape)\n",
    "\n",
    "def get_batches(arr, batch_size, seq_length, encoder=None):\n",
    "    \"\"\"\n",
    "    Divide 1 feature sequence data into batches. Each batch will contain\n",
    "    `n=batch_size` sequences, each with length `m=seq_len`.\n",
    "    \"\"\"\n",
    " \n",
    "    n_chars   = batch_size * seq_length          # -> Total # chars per batch\n",
    "    n_batches = int(np.floor(len(arr)/ n_chars)) # -> Total batches possible \n",
    "    n_keep    = n_chars * n_batches              # -> Cutoff for even batches\n",
    "    \n",
    "    inputs  = arr[:n_keep]\n",
    "    targets = create_targets(arr)[:n_keep]\n",
    "    \n",
    "    if encoder is not None:\n",
    "        n_cats = len(encoder.categories_[0])\n",
    "        inputs = encoder.transform(inputs.reshape(-1, 1))\n",
    "        inputs = inputs.reshape(batch_size, -1, n_cats)\n",
    "    else:\n",
    "        inputs = inputs.reshape(batch_size, -1)\n",
    "        \n",
    "    targets = targets.reshape(batch_size, -1)\n",
    "    \n",
    "    for b in range(0, inputs.shape[1], seq_length): \n",
    "        x = torch.tensor(inputs[:, b: b + seq_length], dtype=torch.float32)\n",
    "        y = torch.tensor(targets[:, b: b + seq_length], dtype=torch.float32)   \n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class charNN(nn.Module):\n",
    "    def __init__(self, vocab, hidden_size, n_layers, dropout=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab = vocab\n",
    "        self.int2char = dict(enumerate(vocab))\n",
    "        self.char2int = {ch : i for i, ch in self.int2char.items()}\n",
    "        self.vocab_length = len(vocab)\n",
    "        \n",
    "        oh_keys = np.array([i for i, _ in enumerate(vocab)])\n",
    "        self.encoder = OneHotEncoder(sparse=False).fit(oh_keys.reshape(-1, 1))\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.vocab_length, hidden_size, n_layers, batch_first=True)\n",
    "        self.fc   = nn.Linear(hidden_size, self.vocab_length)\n",
    "        self.do   = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        x, hidden = self.lstm(x, hidden)     # -> (n_batches, seq_len, hidden_size)\n",
    "        x = self.do(x)\n",
    "        x = x.reshape(-1, self.hidden_size)  # -> (n_batches * seq_len, hidden_size)\n",
    "        x = self.fc(x)                       # -> (n_batches * seq_len, vocab_length)\n",
    "        return x, hidden    \n",
    "    \n",
    "    def train_model(self, train_data, batch_size, \n",
    "                    seq_len, epochs, lr=0.001, clip=5, valid=None):\n",
    "           \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self = self.to(device)\n",
    "        \n",
    "        opt = optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        valid_loss = []\n",
    "        train_loss = []\n",
    "        \n",
    "        train_data = np.array([self.char2int[c] for c in train_data])\n",
    "        if valid is not None:\n",
    "            valid = np.array([self.char2int[c] for c in valid])\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            \n",
    "            running_t_loss = 0\n",
    "            running_v_loss = 0\n",
    "            \n",
    "            if valid is not None:\n",
    "                v_hs = None\n",
    "                self.eval()\n",
    "                with torch.no_grad():\n",
    "                    batches = get_batches(valid, batch_size, seq_len, encoder=self.encoder)\n",
    "                    for x, y in batches:\n",
    "                        x, y = x.to(device), y.to(device)\n",
    "                        out, v_hs = self(x, v_hs)\n",
    "                        loss = criterion(out, y.view(batch_size * seq_len).long())\n",
    "                        running_v_loss += loss.item()\n",
    "            \n",
    "            self.train()\n",
    "            hs = None\n",
    "            batches = get_batches(train_data, \n",
    "                                  batch_size, \n",
    "                                  seq_len, \n",
    "                                  encoder=self.encoder)\n",
    "            \n",
    "            for x, y in batches:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                opt.zero_grad()\n",
    "                out, hs = self(x, hs)\n",
    "                hs = tuple([h_n.data for h_n in hs])\n",
    "                loss = criterion(out, y.view(batch_size * seq_len).long())\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(self.parameters(), clip)\n",
    "                opt.step()\n",
    "                running_t_loss += loss.item()\n",
    "            \n",
    "            train_loss.append(np.mean(running_t_loss))\n",
    "            valid_loss.append(np.mean(running_v_loss))\n",
    "            \n",
    "            if e % np.floor(epochs / 10) == 0:\n",
    "                print(f'------------ EPOCH {e} --------------')\n",
    "                print(f'Training Loss: {train_loss[-1]}')\n",
    "                print(f'Validation Loss: {valid_loss[-1]}')\n",
    "                try:\n",
    "                    if valid_loss[-1] < valid_loss[-2]:\n",
    "                        print('Validation Loss Decreased')\n",
    "                except IndexError:\n",
    "                    pass\n",
    "        \n",
    "        plt.plot(train_loss, label='Training Loss')\n",
    "        plt.plot(valid_loss, label='Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def predict(self, char, top_k=None, hs=None):\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.to(device)\n",
    "        self.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            int_val = torch.tensor(self.char2int[char])\n",
    "            x = int_val.reshape(-1, 1)\n",
    "            x = self.encoder.transform(x)\n",
    "            x = x.reshape(1, 1, -1)\n",
    "            x = torch.tensor(x, dtype=torch.float32)\n",
    "            x = x.to(device)\n",
    "\n",
    "            hs = None\n",
    "            out, hs = self(x, hs)\n",
    "\n",
    "            ps   = F.softmax(out, dim=1).squeeze()\n",
    "            \n",
    "            if top_k is None:\n",
    "                choices = np.arange(len(self.vocab))\n",
    "            else:\n",
    "                ps, choices = ps.topk(top_k)\n",
    "                choices = choices.cpu().numpy()\n",
    "            \n",
    "            ps = ps.cpu().numpy()\n",
    "            \n",
    "            char = np.random.choice(choices, p=ps/ps.sum())\n",
    "            char = self.int2char[char]\n",
    "\n",
    "        return char, hs\n",
    "    \n",
    "    def sample(self, length, top_k=None, primer='The '):\n",
    "        hs = None\n",
    "        for px in primer:\n",
    "            out, hs = self.predict(px, hs=hs)\n",
    "        \n",
    "        chars = [out]\n",
    "        for ix in range(length):\n",
    "            char, out = self.predict(chars[-1], top_k=top_k, hs=hs)\n",
    "            chars.append(char)\n",
    "        \n",
    "        return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "charNN(\n",
       "  (lstm): LSTM(83, 512, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=83, bias=True)\n",
       "  (do): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = 512\n",
    "n_layers = 2\n",
    "\n",
    "model = charNN(vocab, n_hidden, n_layers, dropout=0.5)\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-c3f4640c070c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mv_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-f9f36ea58172>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self, train_data, batch_size, seq_len, epochs, lr, clip, valid)\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                 \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m                 \u001b[0mhs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mh_n\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mh_n\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wesle\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-f9f36ea58172>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m# -> (n_batches, seq_len, hidden_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# -> (n_batches * seq_len, hidden_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wesle\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wesle\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[0;32m    570\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0;32m    571\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train_model(t_x, 128, 100, 20, valid=v_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_file = 'LSTM_20_epoch.net'\n",
    "\n",
    "checkpoint = {\n",
    "    'vocab'     : model.vocab,\n",
    "    'n_hidden'  : model.hidden_size,\n",
    "    'n_layers'  : model.n_layers,\n",
    "    'state_dict': model.state_dict()\n",
    "}\n",
    "\n",
    "with open(f'saved/{saved_file}', 'wb') as f:\n",
    "    torch.save(checkpoint, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved/LSTM_20_epoch.net', 'rb') as f:\n",
    "    checkpoint = torch.load(f)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = charNN(vocab, checkpoint['n_hidden'], checkpoint['n_layers'])\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eshinenore anathanerinous athonorithathanerinirerareroureronononovele helothanelithout thalonele Alinonelaly thelaneneninene Athy harerithelishininenathirathatelorine tist henarere Alares thigininonot Anes.\\nAlaratelathery\\nTthelone Ts,\"\\nthenelinonenotherinorelithashesthy henone he Tithelathe helinerite he halonalougiges,\" Aly hes Anorithinithelenouthas alove Alarathenely thatharithelithonovas, Alenererithathe haronithe halale Talalares alelinalingeline harene he harerathererashes thary,\" tharenes Alele astelenere Athenouronite henerelinonorely. Ts halerinininores.\\nt are he has as, he Alinenenelathanithonarinonineninathelathinonithes Alinithatherelathanelononenerithe ales... hone ary hinigrithene Alitinatharonerinenenerinothene atenarorine Alinge Ts honelithas Tsthely t\\'thathine t\\'s athelaninone thononithery henonaleneralinenenonitinenes teralone are helenes, Angithathenoverinalinesthares anes Tinonine he Alinorerathatharis honone aras Tstine Arithalerinorothas thonorenithalas Ttheralathe'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sample(1000, top_k=5, primer='The bird sang us a song')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
