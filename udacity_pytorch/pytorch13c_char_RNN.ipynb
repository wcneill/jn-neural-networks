{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model:\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, vocab, n_hidden, n_layers, do=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab    = vocab\n",
    "        self.int2char = {i: ch for i, ch in enumerate(vocab)}\n",
    "        self.char2int = {ch: i for i, ch in self.int2char.items()}\n",
    "        self.encoder  = OneHotEncoder(sparse=False).fit(vocab.reshape(-1, 1))\n",
    "        \n",
    "        self.n_hidden = n_hidden \n",
    "        self.n_layers = n_layers\n",
    "        self.lstm = nn.LSTM(len(vocab), n_hidden, n_layers, batch_first=True, dropout=do)\n",
    "        self.fc   = nn.Linear(n_hidden, len(vocab))\n",
    "        \n",
    "    def forward(self, x, hs=None):\n",
    "        x, hs = self.lstm(x, hs)          # -> (batch_size, seq_len, n_hidden)\n",
    "        x = x.reshape(-1, self.n_hidden)  # -> (batch_size * seq_len, n_hidden)\n",
    "        out = self.fc(x)                  # -> (batch_size * seq_len, vocab_size)\n",
    "        \n",
    "        return out, hs \n",
    "    \n",
    "    def predict(self, char, hs=None):\n",
    "        pass\n",
    "    \n",
    "    def sample():\n",
    "        pass\n",
    "    \n",
    "    def label_encode(self, data):\n",
    "        return np.array([self.char2int[ch] for ch in data])\n",
    "    \n",
    "    def label_decode(self, data):\n",
    "        return np.array([self.int2char[i] for i in data])\n",
    "    \n",
    "    def onehot_encode(self, data):\n",
    "        return self.encoder.transform(data)\n",
    "    \n",
    "    def onehot_decode(self, data):\n",
    "        return self.encoder.inverse_transform(data)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a batching method:\n",
    "def get_batches(data, n_seq, seq_len):\n",
    "    \"\"\"\n",
    "    Takes data of shape (n_samples, n_features), returns batches\n",
    "    of shape (n_seq, seq_len, n_features)\n",
    "    \"\"\"\n",
    "    n_features = data.shape[1]\n",
    "    n_chars    = n_seq * seq_len\n",
    "    n_batches  = int(np.floor(len(data) / n_chars))\n",
    "    n_keep     = n_batches * n_chars\n",
    "    \n",
    "    inputs  = data[:n_keep]\n",
    "    targets = np.append(data[1:], data[0]).reshape(data.shape)\n",
    "    targets = targets[:n_keep]\n",
    "    \n",
    "    inputs = inputs.reshape(n_seq, -1, n_features)\n",
    "    targets = targets.reshape(n_seq, -1, n_features)\n",
    "    \n",
    "    for i in range(0, inputs.shape[1], seq_len):\n",
    "        x = inputs[:, i: i + seq_len]\n",
    "        y = targets[:, i: i + seq_len]\n",
    "        yield x,y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, batch_size, seq_len, epochs, lr=0.01, clip=5, valid=None):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "    \n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if valid is not None:\n",
    "        data  = model.onehot_encode(data.reshape(-1, 1))\n",
    "        valid = model.onehot_encode(valid.reshape(-1, 1))\n",
    "    else:\n",
    "        data  = model.onehot_encode(data.reshape(-1, 1))\n",
    "\n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        hs = None\n",
    "        t_loss = 0\n",
    "        v_loss = 0\n",
    "\n",
    "        for x, y in get_batches(data, batch_size, seq_len):\n",
    "            opt.zero_grad()\n",
    "            x = torch.tensor(x).float()\n",
    "            x = x.to(device)\n",
    "            \n",
    "            out, hs = model(x, hs)\n",
    "            hs = tuple([h.data for h in hs])\n",
    "\n",
    "            # target should not be one-hot encoded for CE Loss\n",
    "            y = y.reshape(-1, len(model.vocab))\n",
    "#             y = model.encoder.inverse_transform(y)\n",
    "            y = model.onehot_decode(y)\n",
    "            y = model.label_encode(y.squeeze())\n",
    "#             y = np.array([model.char2int[ch] for ch in y.squeeze()])\n",
    "            y = torch.from_numpy(y).long().to(device)\n",
    "\n",
    "            loss = criterion(out, y.squeeze())\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            opt.step()\n",
    "            \n",
    "            t_loss += loss.item()\n",
    "            \n",
    "        if valid is not None:\n",
    "            model.eval()\n",
    "            hs = None\n",
    "            with torch.no_grad():\n",
    "                for x, y in get_batches(valid, batch_size, seq_len):\n",
    "\n",
    "                    x = torch.tensor(x).float()\n",
    "                    x = x.to(device)\n",
    "\n",
    "                    # invert one hot encoding of for use by cross-entropy loss function\n",
    "                    y = y.reshape(-1, len(model.vocab))\n",
    "#                     y = model.encoder.inverse_transform(y)\n",
    "                    y = model.onehot_decode(y)\n",
    "#                     y = np.array([model.char2int[ch] for ch in y.squeeze()])\n",
    "                    y = model.label_encode(y.squeeze())\n",
    "                    y = torch.from_numpy(y).long().to(device)\n",
    "\n",
    "                    out, hs = model(x, hs)\n",
    "                    hs = tuple([h.data for h in hs])\n",
    "\n",
    "                    loss = criterion(out, y.squeeze())\n",
    "                    v_loss += loss.item()\n",
    "\n",
    "                valid_loss.append(np.mean(v_loss))\n",
    "        \n",
    "        train_loss.append(np.mean(t_loss))\n",
    "        \n",
    "        if e % 2 == 0:\n",
    "            print(f'------- Epoch {e} ---------')\n",
    "            print(f'Training Loss: {train_loss[-1]}')\n",
    "            if valid_loss:\n",
    "                print(f'Valid Loss: {valid_loss[-1]}')\n",
    "            \n",
    "    plt.plot(train_loss, label=\"Training\")\n",
    "    plt.plot(valid_loss, label=\"Validation\")\n",
    "    plt.title(\"Loss vs Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1786701,), (198522,))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data from file:\n",
    "with open('data/texts/anna.txt') as data:\n",
    "    text = data.read()\n",
    "\n",
    "# get unique characters in text \n",
    "vocab = np.array(sorted(set(text)))\n",
    "\n",
    "# split training and validation sets. Convert text to NumPy arrays\n",
    "split_idx = int(np.floor(0.1 * len(encoded)))\n",
    "trainset = np.array(list(text[:-split_idx]))\n",
    "validset = np.array(list(text[-split_idx:]))\n",
    "trainset.shape, validset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (lstm): LSTM(83, 390, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (fc): Linear(in_features=390, out_features=83, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = 390\n",
    "n_layers = 2\n",
    "\n",
    "model = Network(vocab, n_hidden, n_layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Epoch 0 ---------\n",
      "Training Loss: 435.3617558479309\n",
      "Valid Loss: 46.715338945388794\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-33f82d60fa04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-68-5a93e1f91ace>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data, batch_size, seq_len, epochs, lr, clip, valid)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mparam_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mtotal_norm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mparam_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_norm\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mclip_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "seq_len = 100\n",
    "epochs = 3\n",
    "lr = 0.01\n",
    "\n",
    "train(model, trainset, batch_size, seq_len, epochs, lr=lr, valid=validset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'vocab'   : model.vocab,\n",
    "    'n_hidden': model.n_hidden,\n",
    "    'n_layers': model.n_layers,\n",
    "    'state'   : model.state_dict()\n",
    "}\n",
    "\n",
    "filepath = 'saved/LSTM_390_nodes_30_epochs.net'\n",
    "\n",
    "with open(filepath, 'wb') as f:\n",
    "    torch.save(checkpoint, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, vocab, char, top_k=None, hs=None):\n",
    "    \n",
    "    int2char = {i: ch for i, ch in enumerate(vocab)}\n",
    "    char2int = {ch: i for i, ch in int2char.items()}\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    encoder = OneHotEncoder(sparse=False).fit(model.vocab)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        char = char2int[char]\n",
    "        x = torch.tensor(char)\n",
    "        x = x.reshape(-1, 1)\n",
    "        x = encoder.transform(x)\n",
    "        x = x.reshape(1, 1, -1)\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        x = x.to(device)\n",
    "\n",
    "        out, hs = model(x, hs)\n",
    "\n",
    "        ps   = F.softmax(out, dim=1).squeeze()\n",
    "        \n",
    "        if top_k is None:\n",
    "            choices = np.arange(len(model.vocab))\n",
    "        else:\n",
    "            ps, choices = ps.topk(top_k)\n",
    "            choices = choices.cpu().numpy()\n",
    "\n",
    "        ps = ps.cpu().numpy()\n",
    "        char = np.random.choice(choices, p=ps/ps.sum())\n",
    "        char = int2char[char]\n",
    "\n",
    "    return char, hs\n",
    "\n",
    "def sample(model, length, vocab, top_k=None, primer='The '):\n",
    "    print([int2char[i.item()] for i in model.vocab])\n",
    "    hs = None\n",
    "    for px in primer:\n",
    "        out, hs = predict(model, vocab, px, hs=hs)\n",
    "\n",
    "    chars = [out]\n",
    "    for ix in range(length):\n",
    "        char, out = predict(model, vocab, chars[-1], top_k=top_k, hs=hs)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"thinofrofrinofo'_nofrexofrevevevofofamunevinevofrofofonofrononofanofofonofofofofathevonofvinonofrevofrofanononofrevevinononofofelinofofofofrawheisofofofrenonofrevinofrashupefofouprevononithevofoneinofofoupracatofofofofofothinofreagofofofreveawhithevinonofofonevinofofreleevinofofofrofrofouponinevitofrofrinonofofofofofofanonexoupopefrevinofreafovinoupevofithevofrinofonexofofofounonovevevitoflithinofofonofrevevinoflinofatofofevanofrofofabyofonevafofonohitofofonexofouprexitofofofrabyofofrinexinoflanofofofroflinofroupronofofofrevevevofrofofrofofofofofreanonofofobanonupafrofofoflofofofofofofrexinevofrevevofanofrexofe pofrevexupeyeevelinononofrevofrofronofrofraglanonofinofreforinofonofofomofritoupenesinofofrexawinofoneanofrevinofofrexofrofofofrevitheagofofonononevevevinoupeinofinodinorofofrabyofofrevevinofonofofovinofinofofhinofreanexofrunofrexofronofofafrithefrofofrexova tofanofrashinofofrevevofritofofofreanofrofroupanonofa Wevinoninofofoupuprevevoforuprinofonofofofofrevofofofinofreagrexonofo\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(sorted(set(text)))\n",
    "sample(model, 1000, vocab, top_k=None, primer=\"And Victoria said \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
