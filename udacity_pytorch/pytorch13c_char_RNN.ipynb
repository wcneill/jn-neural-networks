{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model:\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, vocab, n_hidden, n_layers, do=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab    = vocab\n",
    "        self.int2char = {i: ch for i, ch in enumerate(vocab)}\n",
    "        self.char2int = {ch: i for i, ch in self.int2char.items()}\n",
    "        self.encoder  = OneHotEncoder(sparse=False).fit(vocab.reshape(-1, 1))\n",
    "        \n",
    "        self.n_hidden = n_hidden \n",
    "        self.n_layers = n_layers\n",
    "        self.lstm = nn.LSTM(len(vocab), n_hidden, n_layers, batch_first=True, dropout=do)\n",
    "        self.fc   = nn.Linear(n_hidden, len(vocab))\n",
    "        \n",
    "    def forward(self, x, hs=None):\n",
    "        x, hs = self.lstm(x, hs)          # -> (batch_size, seq_len, n_hidden)\n",
    "        x = x.reshape(-1, self.n_hidden)  # -> (batch_size * seq_len, n_hidden)\n",
    "        out = self.fc(x)                  # -> (batch_size * seq_len, vocab_size)\n",
    "        \n",
    "        return out, hs \n",
    "    \n",
    "    def predict(self, char, top_k=None, hs=None):\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.to(device)\n",
    "        self.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x = np.array([char])\n",
    "            x = x.reshape(-1, 1)\n",
    "            x = self.onehot_encode(x)\n",
    "            x = x.reshape(1, 1, -1)\n",
    "            x = torch.tensor(x, dtype=torch.float32)\n",
    "            x = x.to(device)\n",
    "\n",
    "            out, hs = self(x, hs)\n",
    "\n",
    "            ps   = F.softmax(out, dim=1).squeeze()\n",
    "            \n",
    "            if top_k is None:\n",
    "                choices = np.arange(len(self.vocab))\n",
    "            else:\n",
    "                ps, choices = ps.topk(top_k)\n",
    "                choices = choices.cpu().numpy()\n",
    "            \n",
    "            ps = ps.cpu().numpy()\n",
    "            \n",
    "            char = np.random.choice(choices, p=ps/ps.sum())\n",
    "            char = self.int2char[char]\n",
    "\n",
    "        return char, hs\n",
    "    \n",
    "    \n",
    "    def sample(self, length, top_k=None, primer='And Victoria sang '):\n",
    "        hs = None\n",
    "        for px in primer:\n",
    "            out, hs = self.predict(px, hs=hs)\n",
    "        \n",
    "        chars = [ch for ch in primer]\n",
    "        for ix in range(length):\n",
    "            char, hs = self.predict(chars[-1], top_k=top_k, hs=hs)\n",
    "            chars.append(char)\n",
    "        \n",
    "        return ''.join(chars)\n",
    "    \n",
    "    \n",
    "    def label_encode(self, data):\n",
    "        return np.array([self.char2int[ch] for ch in data])\n",
    "    \n",
    "    \n",
    "    def label_decode(self, data):\n",
    "        return np.array([self.int2char[i] for i in data])\n",
    "    \n",
    "    \n",
    "    def onehot_encode(self, data):\n",
    "        return self.encoder.transform(data)\n",
    "    \n",
    "    \n",
    "    def onehot_decode(self, data):\n",
    "        return self.encoder.inverse_transform(data)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a batching method:\n",
    "def get_batches(data, n_seq, seq_len):\n",
    "    \"\"\"\n",
    "    Takes data of shape (n_samples, n_features), returns batches\n",
    "    of shape (n_seq, seq_len, n_features)\n",
    "    \"\"\"\n",
    "    n_features = data.shape[1]\n",
    "    n_chars    = n_seq * seq_len\n",
    "    n_batches  = int(np.floor(len(data) / n_chars))\n",
    "    n_keep     = n_batches * n_chars\n",
    "    \n",
    "    inputs  = data[:n_keep]\n",
    "    targets = np.append(data[1:], data[0]).reshape(data.shape)\n",
    "    targets = targets[:n_keep]\n",
    "    \n",
    "    inputs = inputs.reshape(n_seq, -1, n_features)\n",
    "    targets = targets.reshape(n_seq, -1, n_features)\n",
    "    \n",
    "    for i in range(0, inputs.shape[1], seq_len):\n",
    "        x = inputs[:, i: i + seq_len]\n",
    "        y = targets[:, i: i + seq_len]\n",
    "        yield x,y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, batch_size, seq_len, epochs, lr=0.01, clip=5, valid=None):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "    \n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if valid is not None:\n",
    "        data  = model.onehot_encode(data.reshape(-1, 1))\n",
    "        valid = model.onehot_encode(valid.reshape(-1, 1))\n",
    "    else:\n",
    "        data  = model.onehot_encode(data.reshape(-1, 1))\n",
    "\n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        hs = None\n",
    "        t_loss = 0\n",
    "        v_loss = 0\n",
    "\n",
    "        for x, y in get_batches(data, batch_size, seq_len):\n",
    "            opt.zero_grad()\n",
    "            x = torch.tensor(x).float()\n",
    "            x = x.to(device)\n",
    "            \n",
    "            out, hs = model(x, hs)\n",
    "            hs = tuple([h.data for h in hs])\n",
    "\n",
    "            # invert one-hot of targets for use by cross-entropy loss function\n",
    "            y = y.reshape(-1, len(model.vocab))\n",
    "            y = model.onehot_decode(y)\n",
    "            y = model.label_encode(y.squeeze())\n",
    "            y = torch.from_numpy(y).long().to(device)\n",
    "\n",
    "            loss = criterion(out, y.squeeze())\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            opt.step()\n",
    "            \n",
    "            t_loss += loss.item()\n",
    "            \n",
    "        if valid is not None:\n",
    "            model.eval()\n",
    "            hs = None\n",
    "            with torch.no_grad():\n",
    "                for x, y in get_batches(valid, batch_size, seq_len):\n",
    "\n",
    "                    x = torch.tensor(x).float()\n",
    "                    x = x.to(device)\n",
    "\n",
    "                    # invert one-hot of targets for use by cross-entropy loss function\n",
    "                    y = y.reshape(-1, len(model.vocab))\n",
    "                    y = model.onehot_decode(y)\n",
    "                    y = model.label_encode(y.squeeze())\n",
    "                    y = torch.from_numpy(y).long().to(device)\n",
    "\n",
    "                    out, hs = model(x, hs)\n",
    "                    hs = tuple([h.data for h in hs])\n",
    "\n",
    "                    loss = criterion(out, y.squeeze())\n",
    "                    v_loss += loss.item()\n",
    "\n",
    "                valid_loss.append(np.mean(v_loss))\n",
    "        \n",
    "        train_loss.append(np.mean(t_loss))\n",
    "        \n",
    "        if e % 2 == 0:\n",
    "            print(f'------- Epoch {e} ---------')\n",
    "            print(f'Training Loss: {train_loss[-1]}')\n",
    "            if valid_loss:\n",
    "                print(f'Valid Loss: {valid_loss[-1]}')\n",
    "            \n",
    "    plt.plot(train_loss, label=\"Training\")\n",
    "    plt.plot(valid_loss, label=\"Validation\")\n",
    "    plt.title(\"Loss vs Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1786701,), (198522,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data from file:\n",
    "with open('data/texts/anna.txt') as data:\n",
    "    text = data.read()\n",
    "\n",
    "# get unique characters in text \n",
    "vocab = np.array(sorted(set(text)))\n",
    "\n",
    "# split training and validation sets. Convert text to NumPy arrays\n",
    "split_idx = int(np.floor(0.1 * len(text)))\n",
    "trainset = np.array(list(text[:-split_idx]))\n",
    "validset = np.array(list(text[-split_idx:]))\n",
    "trainset.shape, validset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (lstm): LSTM(83, 390, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (fc): Linear(in_features=390, out_features=83, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = 390\n",
    "n_layers = 2\n",
    "\n",
    "model = Network(vocab, n_hidden, n_layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Epoch 0 ---------\n",
      "Training Loss: 146.75550657510757\n",
      "Valid Loss: 18.77520525455475\n",
      "------- Epoch 2 ---------\n",
      "Training Loss: 143.57203900814056\n",
      "Valid Loss: 18.782105326652527\n",
      "------- Epoch 4 ---------\n",
      "Training Loss: 142.20537877082825\n",
      "Valid Loss: 18.79310667514801\n",
      "------- Epoch 6 ---------\n",
      "Training Loss: 141.17436909675598\n",
      "Valid Loss: 18.854512333869934\n",
      "------- Epoch 8 ---------\n",
      "Training Loss: 140.2795495390892\n",
      "Valid Loss: 18.914209842681885\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "seq_len = 100\n",
    "epochs = 10\n",
    "lr = 0.001\n",
    "\n",
    "train(model, trainset, batch_size, seq_len, epochs, lr=lr, valid=validset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'vocab'   : model.vocab,\n",
    "    'n_hidden': model.n_hidden,\n",
    "    'n_layers': model.n_layers,\n",
    "    'state'   : model.state_dict()\n",
    "}\n",
    "\n",
    "filepath = 'saved/LSTM_390_nodes_25_epochs.net'\n",
    "\n",
    "with open(filepath, 'wb') as f:\n",
    "    torch.save(checkpoint, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('saved/LSTM_390_nodes_25_epochs.net', 'rb') as f:\n",
    "    checkpoint = torch.load(f)\n",
    "\n",
    "model = Network(vocab, checkpoint['n_hidden'], checkpoint['n_layers'])\n",
    "model.load_state_dict(checkpoint['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = model.sample(1000, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And Victoria sang he saw that it was a long\n",
      "while, to her face, and he concealed her. She had not supposed that she was told\n",
      "the same thing had been\n",
      "so firmly\n",
      "and husbands from his comrades. Tenthed the stream at the moment in the point of plangers, was the same step over the steps.\n",
      "\n",
      "\"Well, I'm a machine, but I am to stand to\n",
      "see you and that her son have no more.\"\n",
      "\n",
      "\"Oh, no!\" she added, letting in her strong arms.\n",
      "\n",
      "\"The second moment's saying how to do it, but it's to be so much!\" said the\n",
      "driving and deliberate scarcely, shrugging officers, with a smile alone all the\n",
      "same thing that had set to the man in his face with a smile to Varenka. Alexey\n",
      "Alexandrovitch had tried not to get them. And the family was so strength.\n",
      "\n",
      "\n",
      "\n",
      "Chapter 29\n",
      "\n",
      "\n",
      "When he was tried to disten on, a spiritualist which is, they were aware, and the stretch of color, and her mother's secretary had never been dreaming. She was a conversation that still more, while\n",
      "a short-conversation or his\n",
      "face, and the dog that had been determining the \n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
